# 1. 感想

spark是面向数据集密集型进行分布式集群计算的。能够处理大型的数据集。

多次扫描相同的数据集时，只需要在首次访问时加载它到内存，后面的访问直接从内存中获取。加快了处理的速度。

# 2. 相关问题

## 1. 一个对象集很大，分在不同机器上，那么对这个数据集运算的时候做的呢？

```scala
将数据集存放在hdfs文件系统里面。
创建相关计算的驱动程序。
闭包函数，闭包既可以用来定义一个分布式数据集，也可以用来传递reduce这样的操作。
val file = spark.textFile("hdfs://...") 
...
val count = ones.reduce(_+_) 
由驱动程序自动分发闭包函数给集群里面的节点进行相关的计算。
Spark可以创建两种共享变量：广播变量和累加器。
最后结果返回给驱动程序进行汇总。
```

## 2.既然数据集很大，分在不同数据集，而且Spark目的是并行处理这些数据，那么什么情况可以并行，什么情况不可以并行？

```
可以并行处理：
计数之类的统计操作可以并行处理。
因为计算是直接在原始数据集上进行统计计算，而数据集是分布式存储的，每个节点可以对存在本地的block进行计算。

不可以并行处理：
每次处理后的结果数据集很大的时候。（比如删除每条数据里面的句号，或者在特定位置增加一个逗号）
因为每次计算结果数据集很大的时候，不能存在内存里面，需要存在hdfs上面，下次计算的时候需要重新读取。
```

## 3.如果在数据集上做运算的时候，该机器挂掉了， 此时会出现什么情况呢？

>   Spark 使用RDD对象中捕获的沿袭信息来重建RDD的丢失分区。这意味着只需要重新计算丢失的分区，并且可以在不同节点上并行地重新计算它们，而无需将程序还原到检查点。
>
>   在MappedDataset中，分区和首选位置与父级相同，但是迭代器将map函数应用于父级的元素。
>
>   在CachedDataset中，`getIterator`方法查找转换后的分区的本地缓存副本，并且每个分区的首选位置开始时均与父级的首选位置相等，但是在某个节点上缓存分区之后进行更新，以便更好地重复使用该节点。
>   它的分区将从其父数据集中重新读取，并最终缓存到其他节点上。

```
如果一个节点发生故障，它的分区将从其父数据集中重新读取，并最终缓存到其他节点上。
会重新计算丢失节点上的数据分区并在其他节点上并行缓存。
```



