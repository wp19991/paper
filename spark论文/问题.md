### 1. 一个对象集很大，分在不同机器上，那么对这个数据集运算的时候做的呢？

```

```

### 2.既然数据集很大，分在不通数据集，而且Spark目的是并行处理这些数据，那么什么情况可以并行，什么情况不可以并行？

```

```

### 3.如果在数据集上做运算的时候，该机器挂掉了， 此时会出现什么情况呢？

>   Spark 使用RDD对象中捕获的沿袭信息来重建RDD的丢失分区。这意味着只需要重新计算丢失的分区，并且可以在不同节点上并行地重新计算它们，而无需将程序还原到检查点。
>
>   在MappedDataset中，分区和首选位置与父级相同，但是迭代器将map函数应用于父级的元素。
>
>   在CachedDataset中，`getIterator`方法查找转换后的分区的本地缓存副本，并且每个分区的首选位置开始时均与父级的首选位置相等，但是在某个节点上缓存分区之后进行更新，以便更好地重复使用该节点。
>   它的分区将从其父数据集中重新读取，并最终缓存到其他节点上。



